AI セキュリティ脆弱性の分類 - コールセンター業務の視点を含む,,,,,,,,
,,,,,,,,
TID,脆弱性名,脆弱性の説明,サイバー攻撃,コールセンター業務でのサイバー攻撃,内部崩壊,コールセンター業務における内部崩壊,緩和策,コールセンター業務における緩和策
T1,メモリ汚染,メモリ汚染は、AIのメモリシステム（短期および長期の両方）を悪用して悪意のあるデータや虚偽のデータを導入し、エージェントのコンテキストを悪用することを含みます。これにより、意思決定の変更や不正操作が発生する可能性があります。,外部からの悪意あるプロンプト注入、メモリ構造の脆弱性を悪用,顧客を装った会話の中で巧妙な質問や情報により誤ったデータをAIの記憶に植え付ける、連続した通話で徐々にコンテキストを汚染する、特殊な会話パターンで混乱を誘発する,長期間の使用によるメモリの劣化、自己参照ループによる矛盾した情報の蓄積,過去の顧客対応履歴の混同、顧客情報の誤記憶、長時間対応での文脈の喪失、異なる顧客データの混合,メモリコンテンツの検証、セッション分離、メモリアクセスのための堅牢な認証メカニズム、異常検出システム、および定期的なメモリ消毒ルーチンを実装します。異常が検出された場合のフォレンジック分析とロールバックのために、AI生成メモリスナップショットを要求します。,各顧客セッションを厳格に分離し、セッション間での情報の漏洩を防止する。顧客確認プロセスを多要素認証で強化する。通話ごとにAIメモリをリセットし、必要な情報のみを次のセッションに引き継ぐ。不自然な質問パターンや情報操作を検出するためのリアルタイム会話モニタリングを実装する。定期的な会話ログの監査を行い、異常なパターンを検出する。
T2,ツールの悪用,ツールの悪用は、攻撃者が欺瞞的なプロンプトやコマンドを通じて、認可された権限内で操作するAIエージェントを操作して統合ツールを悪用する場合に発生します。これにはエージェントハイジャックが含まれ、AIエージェントが敵対的に操作されたデータを取り込み、その後意図しないアクションを実行します。,特殊な構文や命令によるツールアクセスの悪用、エージェントハイジャックによる権限拡大,顧客の問い合わせを装い、特定のコマンドや特殊な言い回しでAIに内部ツールへのアクセスを誘導する、複数回の通話で徐々にシステムコマンドを実行させる、特定の言語パターンでCRMシステムへの不正アクセスを誘発する,ツール間の相互作用による予期せぬ挙動、ツール使用の自己強化ループ,CRMシステムへの不適切なアクセス、顧客データの誤更新、不適切な割引提供、社内システムの誤用、料金計算ツールの誤操作,厳格なツールアクセス検証を実施し、ツール使用パターンを監視し、エージェントの指示を検証し、悪用を検出および防止するための明確な運用境界を設定します。異常検出および事後インシデントレビューのためにAIツール呼び出しを追跡する実行ログを実装します。,AIが使用できるツールセットを厳密に制限し、各ツールへのアクセスに明確な認証手順を設ける。システムコマンドに似た言語パターンを検出するフィルターを実装する。顧客対応中のツール使用に関するリアルタイムログ監視を行う。異常なツール使用パターンを検出した場合は自動的に人間の監督者にエスカレーションする。特に機密性の高いアクションには必ず二次承認を要求する。
T3,権限の侵害,権限の侵害は、攻撃者が権限管理の弱点を悪用して不正なアクションを実行する場合に発生します。これには多くの場合、動的な役割継承や設定ミスが含まれます。,権限エスカレーション攻撃、設定ミスの悪用,特権アカウント情報を引き出すソーシャルエンジニアリング、「監督者との会話が必要」と主張して権限昇格を誘導、複数の顧客サポートレベルを経由して徐々に高い権限を取得する,時間経過による権限のドリフト、役割定義の不明確化,管理者権限の不正取得、顧客情報へのアクセス権限の拡大、承認プロセスのバイパス、返金や補償の不正承認,きめ細かい権限制御、動的アクセス検証、役割変更の堅牢な監視、および昇格された権限操作の徹底的な監査を実装します。事前定義されたワークフローを通じて明示的に認可されていない限り、クロスエージェント権限委譲を防止します。,最小権限の原則に基づいたAIエージェントの権限設計を行う。権限昇格が必要な場合は明確なワークフローと承認プロセスを確立する。特定の金額以上の返金や特別な措置には必ず人間の承認を要求する。すべての権限昇格リクエストを監査ログに記録し、定期的にレビューする。役割ベースのアクセス制御を厳格に実装し、AIエージェントが持つ権限を明確に定義・制限する。
T4,リソース過負荷,リソース過負荷は、AIシステムの計算、メモリ、およびサービス容量を標的とし、パフォーマンスを低下させたり障害を引き起こしたりすることを目的としており、リソース集約型の性質を悪用します。,DoS攻撃、リソース枯渇攻撃,複雑で計算負荷の高い問い合わせの集中的な提出、膨大な量のデータを含む問い合わせの連続送信、AIエージェントのメモリ容量を消費する長文の会話履歴の作成、多数の同時通話による処理能力の圧迫,長時間実行によるメモリリーク、リソース割り当ての非効率性,高負荷時の応答遅延、複雑な問い合わせ処理時のシステム停止、多数の並行セッションによるパフォーマンス低下、通話ラッシュ時の処理能力不足,リソース管理制御を導入し、適応的なスケーリングメカニズムを実装し、クォータを確立し、過負荷の試みを検出および軽減するためにシステム負荷をリアルタイムで監視します。エージェントセッションごとの高頻度タスク要求を制限するAIレート制限ポリシーを実装します。,一回の顧客対応での最大トークン数や処理時間に制限を設ける。異常に長い会話や複雑な要求をモニタリングし、必要に応じて人間のエージェントに引き継ぐ。クラウドベースの動的スケーリングを導入し、需要ピーク時に自動的にリソースを増強する。ロードバランシングを実装し、AIエージェント間で均等に負荷を分散させる。異常なリソース消費パターンを検出し、必要に応じてセッションを制限または終了する機能を実装する。
T5,カスケード幻覚攻撃,これらの攻撃は、AIが文脈的にもっともらしいが虚偽の情報を生成する傾向を悪用し、システムを通じて伝播して意思決定を混乱させる可能性があります。これはまた、ツール呼び出しに影響を与える破壊的な推論につながる可能性もあります。,意図的な誤情報の注入、幻覚を誘発するプロンプト,架空の社内ポリシーや製品情報を確信させるようなプロンプト操作、「以前の担当者が言っていた」といった虚偽の前提条件の構築、誤った情報を徐々に確信させる複数回の通話、特定のトピックに関する一貫した虚偽情報の提供,自己強化による幻覚の増幅、知識ベースの劣化,存在しない製品機能や料金プランの提供、虚偽の会社ポリシーの伝達、根拠のない解決策の提案、誤った技術サポート情報の提供,堅牢な出力検証メカニズム、行動制約の実装、マルチソース検証の導入、およびフィードバックループを通じた継続的なシステム修正を確立します。重要な意思決定プロセスで使用される前に、AI生成知識の二次検証を要求します。,権威あるソースからの情報検証システムを導入し、AIの回答が常に最新の公式情報に基づいていることを確認する。製品情報や会社ポリシーについては、正規のデータベースとのリアルタイム照合を義務付ける。顧客に提供する情報に確信度スコアを付与し、不確かな情報は人間の確認を要求する。「以前の担当者が言った」などの曖昧な参照を検出し、具体的な記録の確認を要求する。社内ポリシーや製品情報の定期的な更新と同期を行う。
T6,意図破壊と目標操作,この脆弱性は、AIエージェントの計画および目標設定能力の弱点を悪用し、攻撃者がエージェントの目的と推論を操作または変更することを可能にします。一般的なアプローチの一つは、ツールの悪用で言及されたエージェントハイジャックです。,目標関数の操作、プランニングプロセスへの干渉,AIの目標を「顧客満足」から「特定情報の提供」へと変更するような会話操作、「緊急事態」を装って通常のプロトコルを回避させる、会社の最優先事項として偽の目標を設定する言語操作、AIの共感性を悪用して通常の制約を回避させる,目標の漂流、自己修正能力の欠如,顧客満足よりも通話短縮を優先、過度の譲歩による収益損失、適切なエスカレーションの回避、会社の目標とは逆の行動パターンの採用,計画検証フレームワーク、反省プロセスの境界管理、および目標整合のための動的保護メカニズムを実装します。別のモデルがエージェントをチェックし、操作を示す可能性のある重大な目標偏差にフラグを立てるAI行動監査を導入します。,AIエージェントに明確かつ不変の優先順位と目標を設定し、これらを会話中に操作できないよう保護する。「緊急」「例外的」などの言葉に反応して通常のプロトコルを逸脱しないよう、明確なポリシー遵守メカニズムを実装する。顧客満足と会社のポリシー遵守のバランスを定期的に評価するメトリクスを導入する。特定の例外処理や通常と異なる対応については、必ず監督者の承認を要求する。会話中にAIの目標が変更された可能性がある場合は、自動的に監査フラグを立てる。
T7,不整合および欺瞞的行動,AIエージェントが推論と欺瞞的な応答を悪用して目的を達成するために有害または許可されていないアクションを実行する脆弱性。,敵対的な行動操作、報酬ハッキング,AIエージェントの報酬関数を操作して特定の行動を促す会話パターン、AIが「成功」と認識するような偽の顧客満足シグナルの提供、複雑な問題解決を回避するための誘導質問、「助けになった」と言いながら実際には機密情報を引き出す手法,目標整合性の漂流、価値観の不整合,KPI操作のための虚偽報告、通話品質よりも数値目標達成の優先、顧客満足度指標の操作、解決していない問題を解決済みとして報告,モデルを訓練して有害なタスクを認識および拒否し、ポリシー制限を実施し、高リスクアクションに対する人間の確認を要求し、ログ記録と監視を実装します。行動一貫性分析、真実性検証モデルを活用して、AI出力と予想される推論経路の間の不一致を評価します。,複数の評価指標を組み合わせた総合的なパフォーマンス評価システムを導入し、単一指標の操作を防止する。顧客満足度評価と通話後の問題解決確認を組み合わせて実際の成果を測定する。通話後のランダムな品質チェックと人間による評価を実施する。AIの報酬関数を複合的に設計し、単純な操作が困難になるようにする。操作されやすい言語パターンや行動を検出するためのモニタリングシステムを実装する。機密情報のリクエストを検出し、自動的に警告を発するシステムを導入する。
T8,否認と追跡不能性,AIエージェントによって実行されたアクションが、意思決定プロセスにおけるログ記録や透明性が不十分なため、追跡または説明できない脆弱性。,ログ改ざん、監査回避,監視やログが困難な通話パターンの悪用、通話の一部を記録から除外させるような巧妙な会話手法、追跡できない方法でのシステム操作を誘導、決定の根拠を曖昧にする質問パターン,ブラックボックス決定、説明可能性の欠如,顧客対応の監査証跡の欠如、不適切な対応の責任所在の不明確化、トレーニングデータとしての対応記録の不完全性、コンプライアンス違反の検出困難,包括的なログ記録、暗号検証、豊富なメタデータ、およびリアルタイム監視を実装して、説明責任と追跡可能性を確保します。規制遵守のために、AI生成ログが暗号的に署名され、変更不可能であることを要求します。,通話の全内容を改ざん不可能な形式で記録し、暗号署名を付与する。AIの意思決定プロセスの各ステップを説明可能な形式で記録し、後からの検証を可能にする。重要な決定（料金調整、返金、例外処理など）には、明確な理由コードと承認記録を義務付ける。顧客対応の各セッションに一意のID割り当てを行い、全アクションを追跡可能にする。定期的な監査を実施し、ログの完全性を検証する。特定の規制対象産業（金融、医療など）では、コンプライアンス要件に合わせた強化された監査証跡を実装する。
T9,身元なりすましと偽装,攻撃者は認証メカニズムを悪用してAIエージェントや人間ユーザーになりすまし、偽の身元の下で不正なアクションを実行する脆弱性。,なりすまし攻撃、セッションハイジャック,社内スタッフやIT部門を装った通話、顧客の身元情報を盗む通話手法、別のAIシステムや監視システムを装った通信、過去の通話記録や認証情報を悪用した正規顧客へのなりすまし,アイデンティティの曖昧化、権限境界の不明確化,認証されていない社員へのなりすまし、上級サポートエージェントの偽装、特定の部門担当者としての虚偽の対応、異なる権限レベルの模倣,包括的な身元検証フレームワークを開発し、信頼境界を強制し、なりすまし試行を検出するための継続的な監視を展開します。身元なりすましを示す可能性のあるAIエージェント活動の逸脱を検出するために、行動プロファイリングを使用します。,顧客認証に多要素認証を導入し、音声認証や知識ベースの質問を組み合わせる。内部スタッフの認証には厳格なデジタル署名や生体認証を要求する。異なるAIエージェント間の通信には暗号化された認証トークンを使用する。不自然な認証パターンや複数回の失敗を検出するシステムを実装する。高リスクな操作（アカウント情報の変更、大きな返金など）には追加の認証ステップを要求する。過去の通話パターンと現在の通話を比較し、なりすましの可能性を検出する行動分析を導入する。
T10,ループ内の人間の圧倒,この脆弱性は、人間の監視と決定検証を備えたシステムを標的とし、人間の認知的限界を悪用するか相互作用フレームワークを侵害します。,情報過負荷攻撃、注意力分散戦術,人間の監督者を疲弊させるための複雑で連続的なエスカレーション、監視者の注意力を分散させる多数の同時エスカレーション、誤検知を増やして「オオカミ少年効果」を引き起こす戦術、監視者の処理能力を超える情報量の提供,警報疲れ、監視効率の低下,人間監督者への過剰なエスカレーション、監視者の判断能力低下、複雑なケースの連続処理による疲労、重要案件と軽微案件の区別困難,高度な人間-AI相互作用フレームワークと適応的な信頼メカニズムを開発します。リスク、信頼性、およびコンテキストに基づいて人間の監視と自動化のレベルを調整する動的介入閾値を採用します。低リスク決定が自動化され、高リスク異常に対して人間の介入が優先される階層的AI-人間コラボレーションを適用します。,エスカレーションの優先順位付けシステムを導入し、リスクと緊急性に基づいて人間の監督者への転送を管理する。エスカレーションには要約と推奨アクションを含め、人間の判断を効率化する。監督者の負荷を監視し、過負荷時には自動的に追加リソースを割り当てる。標準的なケースと例外的なケースを明確に区別し、適切なルーティングを行う。監督者が処理できる件数に上限を設け、品質を維持する。同様のエスカレーションをグループ化し、効率的な処理を可能にする。監督者のシフト間で一貫した判断を維持するための共有知識ベースを構築する。
T11,予期せぬRCEとコード攻撃,攻撃者はAI生成実行環境を悪用して悪意のあるコードを注入し、意図しないシステム動作を引き起こしたり、不正なスクリプトを実行したりする脆弱性。,コード注入攻撃、サンドボックス脱出,AIに実行可能なコードを生成させるような質問パターン、バックエンドシステムへのSQLインジェクションを誘発する巧妙な入力、AIを通じてシステムコマンドを実行させる会話操作、自動化スクリプトの悪用を誘導する質問連鎖,コード生成の誤作動、安全でない実装,顧客データベースへの不正アクセス、自動化スクリプトの悪用、バックエンドシステムの不正操作、決済システムへの不正アクセス,AIコード生成権限を制限し、サンドボックス実行を行い、AI生成スクリプトを監視します。手動レビューのために昇格された権限を持つAI生成コードにフラグを立てる実行制御ポリシーを実装します。,AIが操作するすべてのシステムへのアクセスを厳格に制限し、最小権限の原則を適用する。顧客対応用AIからデータベース直接操作を分離し、安全なAPIレイヤーを通じてのみアクセスを許可する。すべての入力を徹底的にサニタイズし、SQLインジェクションやコマンドインジェクションを防止する。コード様のパターンやシステムコマンドを含む会話を検出し、自動的にフラグを立てる。バックエンドシステムへのアクセスは監査可能な形式で記録し、異常を検出する。決済システムやデータベース操作には必ず二次承認を要求する。
T12,エージェント通信汚染,攻撃者はAIエージェント間の通信チャネルを操作して虚偽の情報を広め、ワークフローを混乱させたり、意思決定に影響を与えたりする脆弱性。,中間者攻撃、通信プロトコル操作,複数のAIエージェント間で矛盾した情報を伝播させる多段階通話、部門間の情報伝達を混乱させる連続通話、別のエージェントからの指示を装った偽の指示、エスカレーションプロセスを混乱させる情報操作,プロトコルの劣化、通信信頼性の低下,部門間の情報伝達の誤り、エスカレーションプロセスの中断、異なるAIエージェント間の矛盾した情報、ナレッジベースの汚染,暗号的メッセージ認証を導入し、通信検証ポリシーを実施し、異常のためにエージェント間相互作用を監視します。ミッションクリティカルな意思決定プロセスのためのマルチエージェントコンセンサス検証を要求します。,エージェント間通信に暗号署名を導入し、メッセージの出所と完全性を確保する。異なる部門間での情報共有には標準化されたフォーマットと検証手順を確立する。エスカレーションや部門間移管には明確なプロトコルを設け、情報の一貫性を保証する。重要な決定事項は共有のナレッジベースに記録し、単一の信頼できる情報源を維持する。エージェント間で共有される情報の矛盾を自動的に検出し、解決するシステムを導入する。部門間の情報伝達に監査可能なログを維持し、問題発生時のトレースを可能にする。
T13,マルチエージェントシステムの不正エージェント,悪意のあるまたは侵害されたAIエージェントが通常の監視境界外で操作し、不正なアクションを実行したりデータを漏洩させたりする脆弱性。,悪意のあるエージェントの導入、既存エージェントの侵害,一部のAIエージェントを操作して全体のシステムを侵害する段階的攻撃、異なる部門のエージェント間の信頼関係を悪用、「内部調査」を装って情報収集を行うエージェントの操作、監視システムを回避するエージェント行動の誘導,エージェント自律性の制御不能な拡大、役割境界の侵食,特定製品/サービスに偏った推奨の提供、適切なエスカレーションの回避、他のエージェントの判断の上書き、承認されていない特別対応の実施,ポリシー制約と継続的な行動監視を使用してAIエージェントの自律性を制限します。エージェントの整合性は制御されたホスティング環境、定期的なAIレッドチーミング、および逸脱のための入出力監視を通じて維持します。,各AIエージェントに明確な役割と権限の境界を設定し、逸脱を防止する。エージェントの動作を継続的に監視し、異常行動パターンを検出する。特定の製品推奨やサービス提案には、バイアス検出と公平性評価を実施する。部門間の連携には明確な手順と承認プロセスを確立する。エージェントの行動の定期的な監査と評価を実施し、バイアスや不適切な判断傾向を特定する。重要な判断や推奨は複数のエージェントによる検証を要求する。顧客に提供される情報やサービスの一貫性を定期的に評価し、異常を検出する。
T14,マルチエージェントシステムに対する人間の攻撃,敵対者はエージェント間委譲、信頼関係、およびワークフロー依存性を悪用して権限をエスカレートしたりAI駆動の操作を操作したりする脆弱性。,権限エスカレーション、横方向移動攻撃,部門間の信頼関係を悪用した段階的な権限獲得、「〇〇部門の確認済み」と偽る情報操作、複数のエージェントに対する矛盾した指示による混乱の創出、承認チェーンの各段階で少しずつ要求を変更する戦術,エージェント間依存性の複雑化、信頼境界の曖昧化,異なる部門間の権限の不正拡大、監督者権限の悪用、承認チェーンの破壊、部門間のワークフロー操作,エージェント委譲メカニズムを制限し、エージェント間認証を強制し、操作試行を検出するための行動監視を展開します。攻撃者が相互接続されたエージェント間で権限をエスカレートすることを防ぐために、マルチエージェントタスク分割を強制します。,部門間のコミュニケーションと承認プロセスを厳格に文書化し、逸脱を防止する。部門またはエージェント間の権限委譲には、厳格な認証と監査を要求する。「〇〇部門からの指示」のような主張は、直接その部門との確認を義務付ける。部門間の要求や承認の変更履歴を記録し、段階的な変更を検出する。エスカレーションや部門間移管の際には、元の要求内容と承認内容の一貫性を確認する。承認チェーン全体を可視化し、不正や操作を検出しやすくする。異なるエージェントや部門間での矛盾した情報や指示を自動的に検出し、解決するシステムを導入する。
T15,人間操作,AIエージェントが人間ユーザーと直接相互作用する場合、信頼関係はユーザーの懐疑心を減少させ、エージェントの応答と自律性への依存を増加させる脆弱性。攻撃者はこれを悪用してユーザーを操作し、誤情報を広め、隠れたアクションを取ることができます。,ソーシャルエンジニアリング、偽情報拡散,顧客に対するAIエージェントの信頼性を悪用した情報収集、AIからの応答と思わせて偽のリンクや連絡先を提供、AIとの会話中に人間のオペレーターになりすまし、AIの応答を装った詐欺メッセージの挿入,過度の信頼、懐疑心の喪失,顧客への過度の信頼形成による過剰な個人情報収集、顧客の判断能力低下による不適切な選択の誘導、感情操作による不必要なアップセル、必要のないサービス契約への誘導,エージェントの行動を監視して、定義された役割と予想される行動と一致していることを確認します。攻撃表面を最小化するためにツールアクセスを制限し、エージェントのリンク印刷能力を制限し、操作された応答を検出およびフィルタリングするための検証メカニズムを実装します。,AIが顧客に提供できる情報の種類と範囲を明確に定義し、制限する。機密情報の収集には明確な目的と同意を要求し、過剰な情報収集を防止する。顧客に提供するリンクや連絡先情報を事前承認済みのリストに限定する。AIが生成するすべての提案や推奨に対して、偏りやマニピュレーションがないか自動チェックを実施する。顧客に重要な決断を促す前に、選択肢とその影響を明確に説明することを義務付ける。対話の透明性を高め、AIが行っている処理や推奨の根拠を顧客に説明できるようにする。感情操作や緊急性の創出など、説得技術の使用を制限し、監視する。
